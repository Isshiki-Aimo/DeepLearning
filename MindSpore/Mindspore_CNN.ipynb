{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#导入相关依赖库\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.context as context\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import  LossMonitor, CheckpointConfig, ModelCheckpoint\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') \n",
    "from mindspore.train.callback import ModelCheckpoint,CheckpointConfig\n",
    "from mindspore import load_checkpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from mindspore.ops import operations as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_TRAIN = \"D:/DL/MNIST/MNIST/train\" # 训练集信息\n",
    "DATA_DIR_TEST = \"D:/DL/MNIST/MNIST/test\" # 测试集信息\n",
    "DATA_DIR = \"D:/DL/MNIST/MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(training=True, batch_size=32, resize=(32, 32),rescale=1/(255*0.3081), shift=-0.1307/0.3081, buffer_size=64,drop_remainder = True):\n",
    "    ds = ms.dataset.MnistDataset(DATA_DIR_TRAIN if training else DATA_DIR_TEST)\n",
    "    \n",
    "\n",
    "    resize_op = CV.Resize(resize)\n",
    "    #rescale方法可以对数据集进行归一化和标准化操作，这里就是将像素值归一到0和1之间，shift参数可以让值域偏移至-0.5和0.5之间\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    \n",
    "    # 利用map操作对原数据集进行调整\n",
    "    ds = ds.map(input_columns=\"image\", operations=[resize_op, rescale_op, hwc2chw_op])\n",
    "    ds = ds.map(input_columns=\"label\", operations=C.TypeCast(ms.int32))\n",
    "    ds = ds.shuffle(buffer_size=buffer_size)\n",
    "    ds = ds.batch(batch_size, drop_remainder)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 in_channel,\n",
    "                 out_channel,\n",
    "                 stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        channel = out_channel\n",
    "        self.conv1 = nn.Conv2d(in_channel, channel,kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel,kernel_size=3, stride=stride)\n",
    "        self.bn2 = nn.BatchNorm2d(channel)\n",
    "        self.conv3 = nn.Conv2d(channel, out_channel,kernel_size=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.down_sample = True\n",
    "        self.down_sample_layer = None\n",
    "        if self.down_sample:\n",
    "            self.down_sample_layer = nn.SequentialCell([nn.Conv2d(channel, out_channel,kernel_size=1, stride=1),\n",
    "                                                        nn.BatchNorm2d(out_channel)])\n",
    "        self.add = P.Add()\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample_layer(identity)\n",
    "        out = self.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, stride=1, pad_mode='same')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, stride=1, pad_mode='same')\n",
    "        self.res1 = ResidualBlock(6, 6, stride=1)\n",
    "        self.res2 = ResidualBlock(16, 16, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(16*8*8, 120,activation='relu')\n",
    "        self.fc2 = nn.Dense(120, 84,activation='relu')\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "        self.dropout = nn.Dropout(0.9)\n",
    "    #构建网络\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.res1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.res2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x,)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ResidualBlock(1, 6, stride=1)\n",
    "# print(net)\n",
    "# input = ms.Tensor(np.ones([1, 1, 32, 32]), ms.float32)\n",
    "# output = net(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 0.20250794291496277\n",
      "epoch: 2 step: 1875, loss is 0.008436259813606739\n",
      "epoch: 3 step: 1875, loss is 0.008808090351521969\n"
     ]
    }
   ],
   "source": [
    "def train(lr=0.01, momentum=0.9, num_epochs=3):\n",
    "    ds_train = create_dataset(training=True,batch_size=32)\n",
    "    net = CNN()\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    loss_cb = LossMonitor(per_print_times=ds_train.get_dataset_size())\n",
    "    metrics = {\n",
    "    'accuracy': nn.Accuracy(),\n",
    "    'loss': nn.Loss(),\n",
    "    'precision': nn.Precision(),\n",
    "    'recall': nn.Recall(),\n",
    "    'f1_score': nn.F1()\n",
    "}\n",
    "    model = Model(net, loss, opt, metrics=metrics)\n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb], dataset_sink_mode=False)\n",
    "    return model\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'accuracy': 0.9827, 'loss': 0.05342913310626706, 'precision': array([0.98487903, 0.98598949, 0.97898758, 0.97365854, 0.99381443,\n",
      "       0.98100559, 0.99263158, 0.97115385, 0.97843943, 0.98756477]), 'recall': array([0.99693878, 0.99207048, 0.99321705, 0.98811881, 0.98167006,\n",
      "       0.98430493, 0.98434238, 0.98249027, 0.97843943, 0.9444995 ]), 'f1_score': array([0.99087221, 0.98902064, 0.98605099, 0.98083538, 0.98770492,\n",
      "       0.98265249, 0.9884696 , 0.97678917, 0.97843943, 0.96555218])}\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    ds_eval = create_dataset(training=False,drop_remainder=False)\n",
    "    metrics = {\n",
    "    'accuracy': nn.Accuracy(),\n",
    "    'loss': nn.Loss(),\n",
    "    'precision': nn.Precision(),\n",
    "    'recall': nn.Recall(),\n",
    "    'f1_score': nn.F1()\n",
    "}\n",
    "    metrics = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    print('Metrics:', metrics)\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_ds = create_dataset(training=False, batch_size=32,drop_remainder=False)\n",
    "test_label = []\n",
    "test_pred = []\n",
    "for data in cifar_ds.create_dict_iterator(num_epochs=3, output_numpy=True):\n",
    "    test_label.extend(data['label'])\n",
    "    input_img = ms.Tensor(data['image'])\n",
    "    output = model.predict(input_img)\n",
    "    output = nn.Softmax(axis=1)(output)\n",
    "    pred = output.asnumpy()\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    test_pred.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96938776e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.02040816e-03, 1.02040816e-03,\n",
       "        1.02040816e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 9.92070485e-01, 2.64317181e-03, 1.76211454e-03,\n",
       "        0.00000000e+00, 8.81057269e-04, 1.76211454e-03, 0.00000000e+00,\n",
       "        8.81057269e-04, 0.00000000e+00],\n",
       "       [1.93798450e-03, 0.00000000e+00, 9.93217054e-01, 0.00000000e+00,\n",
       "        9.68992248e-04, 0.00000000e+00, 0.00000000e+00, 3.87596899e-03,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.95049505e-03, 9.88118812e-01,\n",
       "        0.00000000e+00, 2.97029703e-03, 0.00000000e+00, 9.90099010e-04,\n",
       "        2.97029703e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.03665988e-03, 0.00000000e+00,\n",
       "        9.81670061e-01, 0.00000000e+00, 2.03665988e-03, 1.01832994e-03,\n",
       "        3.05498982e-03, 1.01832994e-02],\n",
       "       [2.24215247e-03, 0.00000000e+00, 0.00000000e+00, 8.96860987e-03,\n",
       "        0.00000000e+00, 9.84304933e-01, 1.12107623e-03, 1.12107623e-03,\n",
       "        2.24215247e-03, 0.00000000e+00],\n",
       "       [5.21920668e-03, 4.17536534e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.04384134e-03, 5.21920668e-03, 9.84342380e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 4.86381323e-03, 7.78210117e-03, 1.94552529e-03,\n",
       "        0.00000000e+00, 9.72762646e-04, 0.00000000e+00, 9.82490272e-01,\n",
       "        9.72762646e-04, 9.72762646e-04],\n",
       "       [4.10677618e-03, 0.00000000e+00, 3.08008214e-03, 4.10677618e-03,\n",
       "        1.02669405e-03, 5.13347023e-03, 1.02669405e-03, 2.05338809e-03,\n",
       "        9.78439425e-01, 1.02669405e-03],\n",
       "       [1.98216056e-03, 6.93756194e-03, 9.91080278e-04, 1.09018831e-02,\n",
       "        2.97324083e-03, 1.98216056e-03, 0.00000000e+00, 1.98216056e-02,\n",
       "        9.91080278e-03, 9.44499504e-01]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label, test_pred,normalize='true')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,cmap=\"YlGnBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "373151cbc95481ea95ac7d68576d58b9482a31c462ca054c3f25e7238c652c99"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('MindSpore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
